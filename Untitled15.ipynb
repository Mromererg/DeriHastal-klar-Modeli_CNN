{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","gpuType":"A100","mount_file_id":"1ydma5MSJ2lpEWNc-W3bt_CjMq6DUJ-xL","authorship_tag":"ABX9TyOlh4nEgUtV+dB7qpwFvblY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"K8GITkmRKAtJ"},"outputs":[],"source":["# 1. Kaggle API anahtarını yüklemek için (kaggle.json dosyasını Colab'a yüklemen lazım)\n","from google.colab import files\n","files.upload()  # Buradan kendi kaggle.json dosyanı seçip yükle\n","\n","# 2. .kaggle klasörü oluştur ve izinlerini ayarla\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","\n","# 3. Veri setini indir\n","!kaggle datasets download -d sayedhossainjobayer/skin-diseases-dataset --quiet\n","\n","# 4. Zip dosyasını aç\n","!unzip -q skin-diseases-dataset.zip -d skin_diseases\n","\n","# 5. İçeriği kontrol et (az bilgi yazdır)\n","!ls -l skin_diseases\n","\n","\n"]},{"cell_type":"code","source":["import os\n","\n","base_path = \"skin_diseases/DATASET\"\n","for cls in os.listdir(base_path):\n","    cls_path = os.path.join(base_path, cls)\n","    if os.path.isdir(cls_path):\n","        print(f\"{cls}: {len(os.listdir(cls_path))} görsel\")\n","\n"],"metadata":{"id":"0OUyjlLDtiik"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","dataset_path = 'skin_diseases/DATASET'\n","class_counts = {}\n","\n","for class_name in os.listdir(dataset_path):\n","    class_dir = os.path.join(dataset_path, class_name)\n","    if os.path.isdir(class_dir):\n","        image_files = [f for f in os.listdir(class_dir) if os.path.isfile(os.path.join(class_dir, f))]\n","        class_counts[class_name] = len(image_files)\n"],"metadata":{"id":"D1OvZQuJlh5M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# class_counts zaten yukarıdaki kodda hesaplandı varsayalım\n","\n","# Sınıfları ve sayıları liste olarak al\n","classes = list(class_counts.keys())\n","counts = list(class_counts.values())\n","\n","# Grafik oluştur\n","plt.figure(figsize=(12, 6))\n","bars = plt.bar(classes, counts, color='skyblue')\n","plt.xlabel('Sınıflar')\n","plt.ylabel('Görsel Sayısı')\n","plt.title('Sınıf Bazında Görsel Sayısı (Dengesiz Veri Seti)')\n","plt.xticks(rotation=45, ha='right')\n","\n","# Her barın üstüne sayıyı yazdır (opsiyonel)\n","for bar in bars:\n","    height = bar.get_height()\n","    plt.text(bar.get_x() + bar.get_width()/2, height + 5, str(height), ha='center', va='bottom')\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"C35Xz8Clwg10"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","import os\n","\n","dataset_path = 'skin_diseases/DATASET'\n","\n","for class_name in os.listdir(dataset_path):\n","    class_dir = os.path.join(dataset_path, class_name)\n","    for img_name in os.listdir(class_dir):\n","        img_path = os.path.join(class_dir, img_name)\n","\n","        # Sadece dosyaları kontrol et\n","        if not os.path.isfile(img_path):\n","            continue\n","\n","        try:\n","            with Image.open(img_path) as img:\n","                img.verify()\n","        except:\n","            print(f\"Hatalı görsel siliniyor: {img_path}\")\n","            os.remove(img_path)\n"],"metadata":{"id":"1H3L3CIetkSm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","dataset_path = 'skin_diseases/DATASET'\n","class_counts = {}\n","\n","for class_name in os.listdir(dataset_path):\n","    class_dir = os.path.join(dataset_path, class_name)\n","    if os.path.isdir(class_dir):\n","        image_files = [f for f in os.listdir(class_dir) if os.path.isfile(os.path.join(class_dir, f))]\n","        class_counts[class_name] = len(image_files)\n","\n","# Sıralı şekilde yazdır\n","for class_name, count in sorted(class_counts.items(), key=lambda x: x[1]):\n","    print(f\"{class_name}: {count} görsel\")\n","\n"],"metadata":{"id":"24RgAOSGtoB3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision import transforms\n","from PIL import Image\n","import os\n","import random\n","\n","augmentation_transforms = transforms.Compose([\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(30),\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n","    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n","])\n","\n","target_count = 1500\n","dataset_path = 'skin_diseases/DATASET'\n","\n","for class_name in os.listdir(dataset_path):\n","    class_dir = os.path.join(dataset_path, class_name)\n","    if not os.path.isdir(class_dir):\n","        continue\n","\n","    images = [f for f in os.listdir(class_dir) if os.path.isfile(os.path.join(class_dir, f))]\n","    current_count = len(images)\n","\n","    if current_count >= target_count:\n","        continue\n","\n","    print(f\"{class_name}: {current_count} görsel → {target_count} yapılacak.\")\n","    needed = target_count - current_count\n","\n","    for i in range(needed):\n","        img_name = random.choice(images)\n","        img_path = os.path.join(class_dir, img_name)\n","\n","        try:\n","            with Image.open(img_path) as img:\n","                img = img.convert(\"RGB\")\n","                aug_img = augmentation_transforms(img)\n","                save_path = os.path.join(class_dir, f\"aug_{i}_{img_name}\")\n","                aug_img.save(save_path)\n","        except Exception as e:\n","            print(f\"Hata: {img_path} | {e}\")\n","\n","\n"],"metadata":{"id":"g_1obTxqtpN_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Örnek sınıf isimleri ve görsel sayıları (bunları kendi verine göre güncelle)\n","class_names = ['Arsenic', 'Acne', 'Eczema', 'Melanoma', 'Normal', 'Psoriasis']\n","image_counts = [1500, 1500, 1500, 1500, 1500, 1500]  # Buraya gerçek sayılar gelecek\n","\n","plt.figure(figsize=(10,6))\n","plt.bar(class_names, image_counts, color='skyblue')\n","plt.xlabel('Sınıf')\n","plt.ylabel('Görsel Sayısı')\n","plt.title('Her Sınıfın Görsel Sayısı (Dengelenmiş)')\n","plt.show()\n"],"metadata":{"id":"f_-gfJJ2v9YU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import shutil\n","from sklearn.model_selection import train_test_split\n","\n","dataset_path = 'skin_diseases/DATASET'\n","train_path = 'skin_diseases/train'\n","val_path = 'skin_diseases/val'\n","\n","# Eğer varsa eski klasörleri temizle\n","if os.path.exists(train_path):\n","    shutil.rmtree(train_path)\n","if os.path.exists(val_path):\n","    shutil.rmtree(val_path)\n","\n","os.makedirs(train_path)\n","os.makedirs(val_path)\n","\n","for class_name in os.listdir(dataset_path):\n","    class_dir = os.path.join(dataset_path, class_name)\n","    if not os.path.isdir(class_dir):\n","        continue\n","\n","    images = [f for f in os.listdir(class_dir) if os.path.isfile(os.path.join(class_dir, f))]\n","    train_imgs, val_imgs = train_test_split(images, test_size=0.2, random_state=42)\n","\n","    # Train klasörüne kopyala\n","    os.makedirs(os.path.join(train_path, class_name))\n","    for img in train_imgs:\n","        shutil.copy(os.path.join(class_dir, img), os.path.join(train_path, class_name, img))\n","\n","    # Val klasörüne kopyala\n","    os.makedirs(os.path.join(val_path, class_name))\n","    for img in val_imgs:\n","        shutil.copy(os.path.join(class_dir, img), os.path.join(val_path, class_name, img))\n","\n","print(\"Train/Validation veri seti oluşturuldu.\")\n"],"metadata":{"id":"yLwv3EvNv_p4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","# Eğitim dönüşümleri (augmentasyon + normalize)\n","train_transforms = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(15),\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406],\n","                         [0.229, 0.224, 0.225])\n","])\n","\n","# Doğrulama dönüşümleri (sadece resize ve normalize)\n","val_transforms = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406],\n","                         [0.229, 0.224, 0.225])\n","])\n","\n","train_dataset = datasets.ImageFolder(train_path, transform=train_transforms)\n","val_dataset = datasets.ImageFolder(val_path, transform=val_transforms)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n","\n","print(f\"Train örnek sayısı: {len(train_dataset)}\")\n","print(f\"Val örnek sayısı: {len(val_dataset)}\")\n"],"metadata":{"id":"Olu_86qnxLtm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torchvision import models\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Kullanılan cihaz:\", device)\n","\n","# Önceden eğitilmiş ResNet50 modelini yükle\n","model = models.resnet50(pretrained=True)\n","\n","# Son katmanı (fully connected) veri setindeki sınıf sayısına göre ayarla\n","num_classes = len(train_dataset.classes)\n","model.fc = nn.Linear(model.fc.in_features, num_classes)\n","\n","model = model.to(device)\n"],"metadata":{"id":"jrSINGo_yQYL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","\n","criterion = nn.CrossEntropyLoss()  # Çok sınıflı sınıflandırma için\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Küçük öğrenme hızı ile başlamak iyi olur\n"],"metadata":{"id":"jPoHxTKHySjt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_one_epoch(model, dataloader, criterion, optimizer, device):\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for inputs, labels in dataloader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * inputs.size(0)\n","        _, preds = torch.max(outputs, 1)\n","        correct += (preds == labels).sum().item()\n","        total += labels.size(0)\n","\n","    epoch_loss = running_loss / total\n","    epoch_acc = correct / total\n","\n","    return epoch_loss, epoch_acc\n","\n","def validate(model, dataloader, criterion, device):\n","    model.eval()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for inputs, labels in dataloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            running_loss += loss.item() * inputs.size(0)\n","            _, preds = torch.max(outputs, 1)\n","            correct += (preds == labels).sum().item()\n","            total += labels.size(0)\n","\n","    epoch_loss = running_loss / total\n","    epoch_acc = correct / total\n","\n","    return epoch_loss, epoch_acc\n"],"metadata":{"id":"N31Lkzy6yT_m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_epochs = 10\n","\n","train_losses = []\n","train_accuracies = []\n","val_losses = []\n","val_accuracies = []\n","\n","for epoch in range(num_epochs):\n","    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n","    val_loss, val_acc = validate(model, val_loader, criterion, device)\n","\n","    train_losses.append(train_loss)\n","    train_accuracies.append(train_acc)\n","    val_losses.append(val_loss)\n","    val_accuracies.append(val_acc)\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs} - \"\n","          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n","          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n"],"metadata":{"id":"ZGji_NhnyV6V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","epochs = range(1, num_epochs + 1)\n","\n","plt.figure(figsize=(12, 5))\n","\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs, train_losses, label='Train Loss')\n","plt.plot(epochs, val_losses, label='Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Loss over Epochs')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs, train_accuracies, label='Train Accuracy')\n","plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.title('Accuracy over Epochs')\n","plt.legend()\n","\n","plt.show()\n"],"metadata":{"id":"QWZ3vzpP1tsE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(model.state_dict(), 'resnet50_skin_disease.pth')\n"],"metadata":{"id":"s5bDYSf-2et9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"resnet50_skin_disease.pth\")\n"],"metadata":{"id":"P_PlWcxCr869"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Eğer drive daha önce mount edilmediyse\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Kaydetme\n","torch.save(model.state_dict(), \"/content/drive/MyDrive/resnet50_skin_disease.pth\")\n"],"metadata":{"id":"OljQdmsAsW5H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"XGIKxquIoAkA"}},{"cell_type":"code","source":["import torch\n","from sklearn.metrics import confusion_matrix, classification_report\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Tüm verileri ve tahminleri toplayalım\n","all_preds = []\n","all_labels = []\n","\n","model.eval()\n","with torch.no_grad():\n","    for images, labels in val_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(images)\n","        _, preds = torch.max(outputs, 1)\n","\n","        all_preds.extend(preds.cpu().numpy())\n","        all_labels.extend(labels.cpu().numpy())\n","\n","# Confusion matrix hesapla\n","cm = confusion_matrix(all_labels, all_preds)\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n","plt.xlabel(\"Tahmin\")\n","plt.ylabel(\"Gerçek\")\n","plt.title(\"Confusion Matrix\")\n","plt.xticks(rotation=45)\n","plt.yticks(rotation=45)\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"QJDo6KerLHpM"},"execution_count":null,"outputs":[]}]}